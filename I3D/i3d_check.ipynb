{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21909ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9664e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c3248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ce44fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ichuviliaeva/.cache/torch/hub/facebookresearch_pytorchvideo_master\n"
     ]
    }
   ],
   "source": [
    "model_name = \"i3d_r50\"\n",
    "model = torch.hub.load(\"facebookresearch/pytorchvideo\", model=model_name, pretrained=True)\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03857ad9",
   "metadata": {},
   "source": [
    "Проверяем, что модель предобучена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f81726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DATA/ichuviliaeva/videos/i3d_experemental\n"
     ]
    }
   ],
   "source": [
    "%cd /DATA/ichuviliaeva/videos/i3d_experemental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a7c7f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-26 06:03:56--  https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10326 (10K) [text/plain]\n",
      "Saving to: ‘kinetics_classnames.json.1’\n",
      "\n",
      "kinetics_classnames 100%[===================>]  10.08K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2023-01-26 06:03:57 (14.3 MB/s) - ‘kinetics_classnames.json.1’ saved [10326/10326]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dc25881",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kinetics_classnames.json\", \"r\") as f:\n",
    "    kinetics_classnames = json.load(f)\n",
    "\n",
    "kinetics_id_to_classname = {}\n",
    "for k, v in kinetics_classnames.items():\n",
    "    kinetics_id_to_classname[v] = str(k).replace('\"', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03e18e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arranging flowers\n"
     ]
    }
   ],
   "source": [
    "print(kinetics_id_to_classname[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bcbf27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose, Lambda\n",
    "from torchvision.transforms._transforms_video import (\n",
    "    CenterCropVideo,\n",
    "    NormalizeVideo,\n",
    ")\n",
    "\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    "    UniformCropVideo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fdccf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "side_size = 256\n",
    "mean = [0.45, 0.45, 0.45]\n",
    "std = [0.225, 0.225, 0.225]\n",
    "crop_size = 256\n",
    "num_frames = 32\n",
    "sampling_rate = 2\n",
    "frames_per_second = 30\n",
    "alpha = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2169ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform =  ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(num_frames),\n",
    "            Lambda(lambda x: x/255.0),\n",
    "            NormalizeVideo(mean, std),\n",
    "            ShortSideScale(\n",
    "                size=side_size\n",
    "            ),\n",
    "            CenterCropVideo(crop_size)\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba896d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_duration = (num_frames * sampling_rate)/frames_per_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3717a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-26 06:03:57--  https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 549197 (536K) [video/mp4]\n",
      "Saving to: ‘archery.mp4.1’\n",
      "\n",
      "archery.mp4.1       100%[===================>] 536.33K   614KB/s    in 0.9s    \n",
      "\n",
      "2023-01-26 06:03:59 (614 KB/s) - ‘archery.mp4.1’ saved [549197/549197]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f647c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"archery.mp4\"\n",
    "\n",
    "start_sec = 0\n",
    "end_sec = start_sec + clip_duration\n",
    "\n",
    "video = EncodedVideo.from_path(video_path)\n",
    "\n",
    "video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
    "\n",
    "video_data = transform(video_data)\n",
    "\n",
    "inputs = video_data[\"video\"]\n",
    "inputs = [i.to(device)[None, ...] for i in inputs]\n",
    "inputs = torch.cat(inputs).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8510d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b63257a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([[0.5663, 0.0116, 0.0094, 0.0094, 0.0091]], device='cuda:0',\n",
      "       grad_fn=<TopkBackward>),\n",
      "indices=tensor([[  5, 333, 356, 119, 134]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "post_act = torch.nn.Softmax(dim=1)\n",
    "predicts = post_act(predicts)\n",
    "pred_classes = predicts.topk(k=5)\n",
    "print(pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01722c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: archery, stretching arm, throwing axe, exercising arm, front raises\n"
     ]
    }
   ],
   "source": [
    "pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_classes.indices[0]]\n",
    "print(\"Predicted labels: %s\" % \", \".join(pred_class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccbad5b",
   "metadata": {},
   "source": [
    "да, это было видео про стрельбу из лука -- всё хорошо и модель предобучена"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
